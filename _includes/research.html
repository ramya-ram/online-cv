<section class="section projects-section">
                <h2 class="section-title"><i class="fa fa-archive"></i>Research</h2>
                <div class="item">
                    <span class="research-title"><span class="project-tagline">Interpretable Transfer Learning</span> 
                    <img class="profile-img" src="{{site.baseurl}}/assets/images/transfer.png" width="400" height="100"/>
                    <p></p>
                    <div class="research-description">
                    Developing intelligent agents that can interact in the real world requires agents to be adaptable to both situations and people. Generalizing to new situations requires successful transfer learning, or the adaptation of prior learned knowledge to new tasks. Adapting to people requires an interpretable medium for human-machine interaction. We are working on developing more interpretable transfer learning algorithms that can later be incorporated into an interactive system.
                    </div>
                </div><!--//item-->
                <div class="item">
                    <img class="profile-img" src="{{site.baseurl}}/assets/images/learningPreferences.png" width="400" height="100"/>
                    <span class="research-title"><span class="project-tagline">Learning Models for Human Preferences</span> 
                    <p></p>
                    <div class="research-description">
                    As robots are integrated more into environments with people, it is essential for robots to adapt to people's preferences. In this work, we develop a framework for automatically learning user models from joint-action demostrations. We first learn human preferences using an unsupervised clustering algorithm and then use inverse reinforcement learning to learn a reward function for each preference. When working with a new user, the hidden preference is inferred online, and the appropriate learned model is used. We demonstrate through human subject experiments on a collaborative refinishing task that the framework supports effective human-robot teaming.
                    </div>
                </div><!--//item-->
                <div class="item">
                    <span class="research-title"><span class="project-tagline">Human-Robot Team Training</span> 
                    <img class="profile-img" src="{{site.baseurl}}/assets/images/perturbTraining.jpg" width="400" height="100"/>
                    <p></p>
                    <div class="research-description">
                    With robots being increasingly incorporated into teams with humans, an important concern is how these joint human-robot teams can be trained effectively. We take inspiration from a human-team training approach called "perturbation training," which requires team members to practice variations of a given task to help their team generalize to new variants of that task. In this work, we formally define the problem of perturbation training for human-robot teams and develop the first end-to-end framework for such training, which incorporates a multi-agent transfer learning algorithm, a human-robot co-learning framework, and a communication protocol. We perform computational and human subject experiments to validate the benefits of our training framework.
                    </div>
                </div><!--//item-->
                
            </section><!--//section-->