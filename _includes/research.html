<section class="section projects-section">
                <h2 class="section-title"><i class="fa fa-archive"></i>Research</h2>
                <div class="item">
                    <span class="research-title"><span class="project-tagline">Human-in-the-loop Simulation to Real World Transfer</span>                   
                    
                    <p></p>
                    <img class="research-img" hspace="7" src="{{site.baseurl}}/assets/images/transfer.png"/> 
                    <div class="research-description">
                    Deploying AI systems safely in the real world is challenging. The rich and complex nature of the open world makes it difficult for machines trained on limited data to adapt and generalize well. The errors that can result from an imperfect model can be extremely costly (e.g., car accidents, high-impact robot collision). We are using human feedback to help reinforcement learning agents better adapt to the real world, leading to safer deployment of these systems. This involves identifying error regions, or blind spots, that occur due to mismatches between simulator and real-world environments and learning to reduce these mistakes through human input. 
                    </div>
                </div><!--//item-->
                <h2 class="section-title"><i class="fa fa-archive"></i>Research</h2>
                <div class="item">
                    <span class="research-title"><span class="project-tagline">Interpretable Transfer Learning</span>                   
                    
                    <p></p>
                    <img class="research-img" hspace="7" src="{{site.baseurl}}/assets/images/transfer.png"/> 
                    <div class="research-description">
                    Developing intelligent agents that can interact in the real world requires agents to be adaptable to both situations and people. Generalizing to new situations requires successful transfer learning, or the adaptation of prior learned knowledge to new tasks. Adapting to people requires an interpretable medium for human-machine interaction. We are working on developing more interpretable transfer learning algorithms that can be incorporated more easily into interactive systems.
                    </div>
                </div><!--//item-->
                <div class="item">
                    <span class="research-title"><span class="project-tagline">Learning Models for Human Preferences</span> 
                    <p></p>
                    <img class="research-img" hspace="7" src="{{site.baseurl}}/assets/images/learningPreferences.png"/>
                    <div class="research-description">
                    As robots are integrated more into environments with people, it is essential for robots to adapt to people's preferences. In this work, we automatically learn user models from joint-action demostrations. We first learn human preferences using an unsupervised clustering algorithm and then use inverse reinforcement learning to learn a reward function for each preference. When working with a new user, the hidden preference is inferred online. We demonstrate through human subject experiments on a collaborative refinishing task that the framework supports effective human-robot teaming.
                    </div>
                </div><!--//item-->
                <div class="item">
                    <span class="research-title"><span class="project-tagline">Human-Robot Team Training</span> 
                    <p></p>
                    <img class="research-img" hspace="7" src="{{site.baseurl}}/assets/images/perturbTraining.jpg"/>
                    <div class="research-description">
                    With a rise in joint human-robot teams, an important concern is how we can effectively train these teams. "Perturbation training" is a training approach used in human teams in which team members practice variations of a task to generalize to new situations. In this work, we develop the first end-to-end framework for human-robot perturbation training, which includes a multi-agent transfer learning algorithm, a human-robot co-learning framework, and a communication protocol. We perform computational and human subject experiments to validate the benefits of our framework.
                    </div>
                </div><!--//item-->
                
            </section><!--//section-->